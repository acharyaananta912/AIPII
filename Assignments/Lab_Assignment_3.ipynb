{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab_Assignment_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayem1997/AIPII/blob/master/Assignments/Lab_Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePDOnMfL7HWV",
        "colab_type": "text"
      },
      "source": [
        "## Introduction to AI Programming II:: Assignment #3 (Lab)  -- Total: 50 pts(Each points are 10 pts.)\n",
        "\n",
        "### Write your information in below. \n",
        "### Student ID:   20192024                     \n",
        "### Name: SAYEM MD KHALEQUZZAMAN CHOWDHURY "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-lp_zSu309l",
        "colab_type": "code",
        "outputId": "cfde7f3b-53cc-466e-92d0-a25c0b396e21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# import tensorflow & keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P-iGK0537fp",
        "colab_type": "code",
        "outputId": "50249cef-102e-48de-9a7c-878c2b409a28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Download mnist data from MNIST server\n",
        "img_rows = 28\n",
        "img_cols = 28\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HU8nFIi4Ew3",
        "colab_type": "code",
        "outputId": "5d8b5ff0-0d81-48d3-8b38-2347ec1a8b5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "# Visualize images of the MNIST dataset\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(x_train[i], cmap='gray', interpolation='none')\n",
        "    plt.title(\"Class {}\".format(y_train[i]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX_Nnd5-4G8t",
        "colab_type": "code",
        "outputId": "498ad4a4-f71e-44aa-9572-887bc94d085e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# check the shape of training data\n",
        "print(x_train.shape)\n",
        "# check the shape of test data\n",
        "print(x_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zvLieso4wP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten training and test datasets to 1-d\n",
        "x_train = x_train.reshape(x_train.shape[0], 784)\n",
        "x_test = x_test.reshape(x_test.shape[0], 784)\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNi9ALPp5gpV",
        "colab_type": "code",
        "outputId": "204e9b79-2213-4a1c-95f0-41a221919560",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train[0].shape, x_test[0].shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((784,), (784,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc7ONnDu5im0",
        "colab_type": "code",
        "outputId": "7baaa4d4-3f15-45a1-add5-3c0b728eb5ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# observe the shapes of training data after the reshape\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 784)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thlYf7Gg5mFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1,2,3,... 10 :One Hot coding\n",
        "num_classes = 10\n",
        "from keras.utils import np_utils\n",
        "# reshape labels categorically\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "#y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqPUM2Lr5pwW",
        "colab_type": "code",
        "outputId": "9d56325b-3ff6-4dea-b717-788a8092394d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(y_train[0])\n",
        "print(y_test[0])\n",
        "y_train.shape,y_test.shape\n",
        "print(x_train.shape[1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnpGPKF45sNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_model(num_layers):\n",
        "    model= Sequential()\n",
        "    if num_layers == 0:\n",
        "        model.add(Dense(output_dim= num_classes, input_dim = x_train.shape[1], activation='softmax'))\n",
        "        model.compile(loss='mse', optimizer = 'sgd', metrics=['accuracy'])\n",
        "        return model\n",
        "    \n",
        "    for i in range(num_layers):\n",
        "        if i == 0:\n",
        "            model.add(Dense(output_dim = 32, input_dim = x_train.shape[1], activation='sigmoid'))\n",
        "        else:\n",
        "            model.add(Dense(output_dim = 10, activation='sigmoid'))\n",
        "    model.add(Dense(output_dim = num_classes, activation=\"softmax\"))\n",
        "    model.compile(loss='mse', optimizer='sgd', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7BpXJOo5-m8",
        "colab_type": "code",
        "outputId": "546ddc85-df6e-4d48-cff6-1e7a3fab630b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "(x_train.shape[1],)\n",
        "#num_hidden_neurons = 32\n",
        "model = make_model(num_layers=1)\n",
        "\n",
        "model.summary()\n",
        "history = model.fit(x_train, y_train, batch_size = 128, epochs = 5, validation_data  =(x_test, y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=784, activation=\"sigmoid\", units=32)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 25,450\n",
            "Trainable params: 25,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 3s 52us/step - loss: 0.0920 - accuracy: 0.1145 - val_loss: 0.0918 - val_accuracy: 0.1163\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0915 - accuracy: 0.1363 - val_loss: 0.0914 - val_accuracy: 0.1385\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0911 - accuracy: 0.1582 - val_loss: 0.0909 - val_accuracy: 0.1608\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0907 - accuracy: 0.1782 - val_loss: 0.0906 - val_accuracy: 0.1802\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0903 - accuracy: 0.1946 - val_loss: 0.0902 - val_accuracy: 0.1971\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWarTulI6DN0",
        "colab_type": "code",
        "outputId": "24d802e3-3119-45ab-96cc-f1f57ad5cd65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#evaluate the test loss\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.09019516682624817\n",
            "Test accuracy: 0.19709999859333038\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LfYCahv6uxu",
        "colab_type": "code",
        "outputId": "452c248c-d902-4a08-fc60-8a6a3a611f2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# test the model through visually debugging the inputs,,  run > twice to see the image\n",
        "# index of your input to test\n",
        "n = 3\n",
        "# see the image by plotting\n",
        "plt.imshow(x_test[n].reshape(28, 28), cmap='Greys', interpolation='nearest')  \n",
        "plt.show()\n",
        "\n",
        "# your model's prediction, is the output correct?\n",
        "print('The Answer is ', model.predict_classes(x_test[n].reshape((1, 28* 28) ) ) )\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The Answer is  [7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLVXu5zs7tji",
        "colab_type": "text"
      },
      "source": [
        "## 1. Report the result of the test loss & accuracy, when we set the dimension(neurons) of hidden layer to (64, 128, 256) with one hidden layer.\n",
        "## *** Default condition : refer in the above codes.. \n",
        "## *** You have to write your codes in another blank area, and write your answer in below.\n",
        "\n",
        "> 들여쓴 블록\n",
        "\n",
        "\n",
        "| dimension |      test loss     |    test accuracy      |\n",
        "|-----------|--------------------|-----------------------|\n",
        "|   64      |            0.08923        |         0.2160              |\n",
        "|-----------|--------------------|-----------------------|\n",
        "|   128     |            0.0887        |        0.2494               | \n",
        "|-----------|--------------------|-----------------------|\n",
        "|   256     |         0.0887           |           0.2224            |\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YMxRSVW7_HC",
        "colab_type": "code",
        "outputId": "0754a3f5-f179-4250-ecd1-57864fdb0275",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Write your answer in here\n",
        "def make_model(num_layers, neurons, act='sigmoid'):\n",
        "    model= Sequential()\n",
        "    if num_layers == 0:\n",
        "        model.add(Dense(output_dim= num_classes, input_dim = x_train.shape[1], activation='softmax'))\n",
        "        model.compile(loss='mse', optimizer = 'sgd', metrics=['accuracy'])\n",
        "        return model\n",
        "    \n",
        "    for i in range(num_layers):\n",
        "            model.add(Dense(output_dim = neurons, input_dim = x_train.shape[1], activation=act))\n",
        "    \n",
        "    model.add(Dense(output_dim = num_classes, activation=\"softmax\"))\n",
        "    \n",
        "    model.compile(loss='mse', optimizer='sgd', metrics=['accuracy'])\n",
        "    return model\n",
        "  \n",
        "dimensions = [64, 128, 256]\n",
        "for dimension in dimensions:\n",
        "  model = make_model(1, dimension, 'sigmoid')\n",
        "  model.summary()\n",
        "  history = model.fit(x_train, y_train, batch_size = 128, epochs = 5, validation_data  =(x_test, y_test))\n",
        "  score = model.evaluate(x_test, y_test, verbose=0)\n",
        "  print('Accuracy for ', dimension, ' number of neorons:')\n",
        "  print('Test loss:', score[0])\n",
        "  print('Test accuracy:', score[1], '\\n\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 64)                50240     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 50,890\n",
            "Trainable params: 50,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=784, activation=\"sigmoid\", units=64)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.0921 - accuracy: 0.0848 - val_loss: 0.0916 - val_accuracy: 0.0840\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 1s 18us/step - loss: 0.0911 - accuracy: 0.0977 - val_loss: 0.0908 - val_accuracy: 0.1018\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.0905 - accuracy: 0.1323 - val_loss: 0.0902 - val_accuracy: 0.1518\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 1s 18us/step - loss: 0.0899 - accuracy: 0.1811 - val_loss: 0.0897 - val_accuracy: 0.1941\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 1s 18us/step - loss: 0.0894 - accuracy: 0.2116 - val_loss: 0.0892 - val_accuracy: 0.2160\n",
            "Accuracy for  64  number of neorons:\n",
            "Test loss: 0.08923925380706788\n",
            "Test accuracy: 0.2160000056028366 \n",
            "\n",
            "\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=784, activation=\"sigmoid\", units=128)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.0917 - accuracy: 0.0909 - val_loss: 0.0909 - val_accuracy: 0.1084\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 1s 18us/step - loss: 0.0905 - accuracy: 0.1543 - val_loss: 0.0901 - val_accuracy: 0.2010\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 1s 18us/step - loss: 0.0899 - accuracy: 0.2068 - val_loss: 0.0896 - val_accuracy: 0.2214\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 1s 18us/step - loss: 0.0894 - accuracy: 0.2233 - val_loss: 0.0891 - val_accuracy: 0.2388\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 1s 18us/step - loss: 0.0889 - accuracy: 0.2380 - val_loss: 0.0887 - val_accuracy: 0.2494\n",
            "Accuracy for  128  number of neorons:\n",
            "Test loss: 0.0887090433716774\n",
            "Test accuracy: 0.24940000474452972 \n",
            "\n",
            "\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 203,530\n",
            "Trainable params: 203,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=784, activation=\"sigmoid\", units=256)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.0918 - accuracy: 0.1049 - val_loss: 0.0908 - val_accuracy: 0.1138\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 1s 18us/step - loss: 0.0903 - accuracy: 0.1451 - val_loss: 0.0900 - val_accuracy: 0.1550\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 1s 18us/step - loss: 0.0897 - accuracy: 0.1729 - val_loss: 0.0895 - val_accuracy: 0.1735\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 1s 18us/step - loss: 0.0893 - accuracy: 0.1902 - val_loss: 0.0891 - val_accuracy: 0.1945\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 1s 18us/step - loss: 0.0889 - accuracy: 0.2106 - val_loss: 0.0888 - val_accuracy: 0.2225\n",
            "Accuracy for  256  number of neorons:\n",
            "Test loss: 0.0887875679731369\n",
            "Test accuracy: 0.2224999964237213 \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCMEPBy09wu8",
        "colab_type": "text"
      },
      "source": [
        "## 2. Report the result of the test loss & accuracy, when we set the number of hidden layer to (2, 4, 8)  \n",
        "## *** Default condition : refer in the above codes and each hidden layer have same neurons(number of neurons: 128) \n",
        "## *** You have to write your codes in another blank area, and write your answer in below.\n",
        "\n",
        "> 들여쓴 블록\n",
        "\n",
        "\n",
        "| layer's num |      test loss     |    test accuracy      |\n",
        "|-------------|--------------------|-----------------------|\n",
        "|   2         |            0.090        |                 0.1155      |\n",
        "|-------------|--------------------|-----------------------|\n",
        "|   4         |             0.0902       |         0.1134              | \n",
        "|-------------|--------------------|-----------------------|\n",
        "|   8         |           0.09017         |                0.10279       |\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SluhPBjM9P3j",
        "colab_type": "code",
        "outputId": "61f693e1-29fd-4e10-9f57-9d1f8c1967f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Write your answer in here \n",
        "layers = [2, 4, 8]\n",
        "for layer in layers:\n",
        "  model = make_model(layer, 128, 'sigmoid')\n",
        "  model.summary()\n",
        "  history = model.fit(x_train, y_train, batch_size = 128, epochs = 5, validation_data  =(x_test, y_test))\n",
        "  score = model.evaluate(x_test, y_test, verbose=0)\n",
        "  print('Accuracy for ', layer, ' number of layers:')\n",
        "  print('Test loss:', score[0])\n",
        "  print('Test accuracy:', score[1], '\\n\\n')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=784, activation=\"sigmoid\", units=128)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.0913 - accuracy: 0.1124 - val_loss: 0.0908 - val_accuracy: 0.1141\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.0905 - accuracy: 0.1126 - val_loss: 0.0904 - val_accuracy: 0.1145\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.0903 - accuracy: 0.1131 - val_loss: 0.0902 - val_accuracy: 0.1145\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.0901 - accuracy: 0.1128 - val_loss: 0.0901 - val_accuracy: 0.1149\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.0901 - accuracy: 0.1129 - val_loss: 0.0900 - val_accuracy: 0.1155\n",
            "Accuracy for  2  number of layers:\n",
            "Test loss: 0.09000792063474655\n",
            "Test accuracy: 0.11550000309944153 \n",
            "\n",
            "\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 151,306\n",
            "Trainable params: 151,306\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0916 - accuracy: 0.0936 - val_loss: 0.0913 - val_accuracy: 0.1135\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0909 - accuracy: 0.1124 - val_loss: 0.0908 - val_accuracy: 0.1135\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0906 - accuracy: 0.1124 - val_loss: 0.0905 - val_accuracy: 0.1135\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0904 - accuracy: 0.1124 - val_loss: 0.0903 - val_accuracy: 0.1135\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0902 - accuracy: 0.1124 - val_loss: 0.0902 - val_accuracy: 0.1135\n",
            "Accuracy for  4  number of layers:\n",
            "Test loss: 0.09020468788146972\n",
            "Test accuracy: 0.11349999904632568 \n",
            "\n",
            "\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_17 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 217,354\n",
            "Trainable params: 217,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0937 - accuracy: 0.1044 - val_loss: 0.0924 - val_accuracy: 0.1028\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.0916 - accuracy: 0.1044 - val_loss: 0.0911 - val_accuracy: 0.1028\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.0908 - accuracy: 0.1044 - val_loss: 0.0906 - val_accuracy: 0.1028\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.0904 - accuracy: 0.1044 - val_loss: 0.0903 - val_accuracy: 0.1028\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0902 - accuracy: 0.1044 - val_loss: 0.0902 - val_accuracy: 0.1028\n",
            "Accuracy for  8  number of layers:\n",
            "Test loss: 0.09017109529972077\n",
            "Test accuracy: 0.10279999673366547 \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrZcRg85_O3j",
        "colab_type": "text"
      },
      "source": [
        "## 3. Report the result of the test loss & accuracy, when we set the number of batch size to (64, 128, 256) \n",
        "## *** Default condition : refer in the above codes,  use \"relu\" activation, dropout rate(0.2) and each hidden layer have same neurons(number of neurons: 256) \n",
        "## *** You have to write your codes in another blank area, and write your answer in below.\n",
        "\n",
        "> 들여쓴 블록\n",
        "\n",
        "\n",
        "| batch size  |      test loss     |    test accuracy      |\n",
        "|-------------|--------------------|-----------------------|\n",
        "|   64        |  0.089791                 |   0.1683                |\n",
        "|-------------|--------------------|-----------------------|\n",
        "|   128       |       0.0899        |        0.1288               | \n",
        "|-------------|--------------------|-----------------------|\n",
        "|   256       |      0.0899574              |            0.103699            |\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-B7cNa7_Dp6",
        "colab_type": "code",
        "outputId": "0d2a5bcc-6b55-4f32-d494-a5b97ac31f84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "# Write your answer in here\n",
        "def make_model(num_layers, neurons, act='sigmoid'):\n",
        "    model= Sequential()\n",
        "    if num_layers == 0:\n",
        "        model.add(Dense(output_dim= num_classes, input_dim = x_train.shape[1], activation='softmax'))\n",
        "        model.compile(loss='mse', optimizer = 'sgd', metrics=['accuracy'])\n",
        "        return model\n",
        "    \n",
        "    for i in range(num_layers):\n",
        "            model.add(Dense(output_dim = neurons, input_dim = x_train.shape[1], activation=act))\n",
        "            model.add(Dropout(0.2))\n",
        "    \n",
        "    model.add(Dense(output_dim = num_classes, activation=\"softmax\"))\n",
        "    \n",
        "    model.compile(loss='mse', optimizer='sgd', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "#fixing previous code\n",
        "\n",
        "batch_sizes = [64, 128, 256]\n",
        "for batch_size in batch_sizes:\n",
        "  model = make_model(8, 256, 'relu')\n",
        "  history = model.fit(x_train, y_train, batch_size = batch_size, epochs = 5, validation_data  =(x_test, y_test))\n",
        "  score = model.evaluate(x_test, y_test, verbose=0)\n",
        "  print('Accuracy for ', batch_size, ' Batch Size:')\n",
        "  print('Test loss:', score[0])\n",
        "  print('Test accuracy:', score[1], '\\n\\n')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=784, activation=\"relu\", units=256)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0901 - accuracy: 0.1052 - val_loss: 0.0899 - val_accuracy: 0.1576\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0899 - val_accuracy: 0.1753\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0900 - accuracy: 0.1091 - val_loss: 0.0899 - val_accuracy: 0.1727\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0900 - accuracy: 0.1102 - val_loss: 0.0898 - val_accuracy: 0.1696\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0900 - accuracy: 0.1138 - val_loss: 0.0898 - val_accuracy: 0.1683\n",
            "Accuracy for  64  Batch Size:\n",
            "Test loss: 0.08979160019159317\n",
            "Test accuracy: 0.16830000281333923 \n",
            "\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0901 - accuracy: 0.0963 - val_loss: 0.0900 - val_accuracy: 0.0934\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 3s 52us/step - loss: 0.0901 - accuracy: 0.0986 - val_loss: 0.0900 - val_accuracy: 0.0941\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 3s 52us/step - loss: 0.0901 - accuracy: 0.1000 - val_loss: 0.0900 - val_accuracy: 0.0988\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 3s 52us/step - loss: 0.0900 - accuracy: 0.1023 - val_loss: 0.0900 - val_accuracy: 0.1134\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 3s 52us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0900 - val_accuracy: 0.1288\n",
            "Accuracy for  128  Batch Size:\n",
            "Test loss: 0.08995107423067093\n",
            "Test accuracy: 0.12880000472068787 \n",
            "\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0900 - accuracy: 0.1023 - val_loss: 0.0900 - val_accuracy: 0.0909\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0901 - accuracy: 0.1035 - val_loss: 0.0900 - val_accuracy: 0.0929\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0900 - accuracy: 0.1064 - val_loss: 0.0900 - val_accuracy: 0.0965\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0900 - accuracy: 0.1048 - val_loss: 0.0900 - val_accuracy: 0.1002\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0900 - accuracy: 0.1033 - val_loss: 0.0900 - val_accuracy: 0.1037\n",
            "Accuracy for  256  Batch Size:\n",
            "Test loss: 0.08995743668079376\n",
            "Test accuracy: 0.10369999706745148 \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXbCwzD_ANrV",
        "colab_type": "text"
      },
      "source": [
        "## 4. Report the result of the test loss & accuracy, when we set the number of epochs to (100, 200, 300)\n",
        "*** Default condition :same with the above problem 3\n",
        "\n",
        "*** You have to write your codes in another blank area, and write your answer in below.\n",
        "\n",
        "\n",
        "| epochs      |      test loss     |    test accuracy      |\n",
        "|-------------|--------------------|-----------------------|\n",
        "|   100       |         0.1818           |  0.8941                     |\n",
        "|-------------|--------------------|-----------------------|\n",
        "|   200       |          0.0072          |   0.9534                    | \n",
        "|-------------|--------------------|-----------------------|\n",
        "|   300       |       0.00527            |   0.9674                    |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tslahpgAhZy",
        "colab_type": "code",
        "outputId": "9a5b4b0c-3a18-4143-bbbb-c5346982cad5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Write your answer in here\n",
        "\n",
        "model = make_model(8, 256, 'relu')\n",
        "history = model.fit(x_train, y_train, batch_size = 64, epochs = 100, validation_data  =(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Accuracy for ', 100, ' epochs:')\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1], '\\n\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=784, activation=\"relu\", units=256)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.0901 - accuracy: 0.0974 - val_loss: 0.0900 - val_accuracy: 0.0683\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0901 - accuracy: 0.1010 - val_loss: 0.0900 - val_accuracy: 0.0713\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0900 - accuracy: 0.1030 - val_loss: 0.0900 - val_accuracy: 0.0785\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0900 - accuracy: 0.1029 - val_loss: 0.0899 - val_accuracy: 0.0929\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0899 - val_accuracy: 0.1167\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0900 - accuracy: 0.1075 - val_loss: 0.0899 - val_accuracy: 0.1424\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0900 - accuracy: 0.1106 - val_loss: 0.0899 - val_accuracy: 0.1689\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0900 - accuracy: 0.1129 - val_loss: 0.0898 - val_accuracy: 0.1963\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0899 - accuracy: 0.1139 - val_loss: 0.0898 - val_accuracy: 0.2217\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0899 - accuracy: 0.1187 - val_loss: 0.0898 - val_accuracy: 0.2430\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0899 - accuracy: 0.1192 - val_loss: 0.0898 - val_accuracy: 0.2606\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0899 - accuracy: 0.1217 - val_loss: 0.0897 - val_accuracy: 0.2769\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0899 - accuracy: 0.1234 - val_loss: 0.0897 - val_accuracy: 0.2930\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0899 - accuracy: 0.1257 - val_loss: 0.0897 - val_accuracy: 0.3029\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0898 - accuracy: 0.1317 - val_loss: 0.0897 - val_accuracy: 0.3134\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0898 - accuracy: 0.1331 - val_loss: 0.0896 - val_accuracy: 0.3200\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0898 - accuracy: 0.1346 - val_loss: 0.0896 - val_accuracy: 0.3261\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0898 - accuracy: 0.1416 - val_loss: 0.0895 - val_accuracy: 0.3297\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0897 - accuracy: 0.1415 - val_loss: 0.0895 - val_accuracy: 0.3328\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0897 - accuracy: 0.1434 - val_loss: 0.0895 - val_accuracy: 0.3341\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0897 - accuracy: 0.1476 - val_loss: 0.0894 - val_accuracy: 0.3345\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0896 - accuracy: 0.1509 - val_loss: 0.0894 - val_accuracy: 0.3325\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0896 - accuracy: 0.1576 - val_loss: 0.0893 - val_accuracy: 0.3304\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0896 - accuracy: 0.1574 - val_loss: 0.0892 - val_accuracy: 0.3284\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0895 - accuracy: 0.1637 - val_loss: 0.0891 - val_accuracy: 0.3245\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0894 - accuracy: 0.1663 - val_loss: 0.0890 - val_accuracy: 0.3188\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0894 - accuracy: 0.1676 - val_loss: 0.0889 - val_accuracy: 0.3141\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0893 - accuracy: 0.1700 - val_loss: 0.0888 - val_accuracy: 0.3082\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0892 - accuracy: 0.1727 - val_loss: 0.0886 - val_accuracy: 0.3031\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0891 - accuracy: 0.1760 - val_loss: 0.0884 - val_accuracy: 0.2995\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0889 - accuracy: 0.1809 - val_loss: 0.0882 - val_accuracy: 0.2941\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0888 - accuracy: 0.1813 - val_loss: 0.0879 - val_accuracy: 0.2907\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0885 - accuracy: 0.1855 - val_loss: 0.0874 - val_accuracy: 0.2867\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0882 - accuracy: 0.1896 - val_loss: 0.0869 - val_accuracy: 0.2853\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0878 - accuracy: 0.1931 - val_loss: 0.0862 - val_accuracy: 0.2817\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0872 - accuracy: 0.1997 - val_loss: 0.0851 - val_accuracy: 0.2816\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0865 - accuracy: 0.2088 - val_loss: 0.0837 - val_accuracy: 0.2820\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0854 - accuracy: 0.2222 - val_loss: 0.0820 - val_accuracy: 0.2860\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0840 - accuracy: 0.2323 - val_loss: 0.0802 - val_accuracy: 0.2924\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0826 - accuracy: 0.2508 - val_loss: 0.0788 - val_accuracy: 0.3018\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0813 - accuracy: 0.2674 - val_loss: 0.0776 - val_accuracy: 0.3153\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0801 - accuracy: 0.2855 - val_loss: 0.0767 - val_accuracy: 0.3270\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0790 - accuracy: 0.3028 - val_loss: 0.0759 - val_accuracy: 0.3405\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0782 - accuracy: 0.3164 - val_loss: 0.0752 - val_accuracy: 0.3493\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0773 - accuracy: 0.3321 - val_loss: 0.0747 - val_accuracy: 0.3568\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0768 - accuracy: 0.3424 - val_loss: 0.0742 - val_accuracy: 0.3650\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0761 - accuracy: 0.3517 - val_loss: 0.0738 - val_accuracy: 0.3702\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0756 - accuracy: 0.3620 - val_loss: 0.0734 - val_accuracy: 0.3752\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0751 - accuracy: 0.3693 - val_loss: 0.0730 - val_accuracy: 0.3793\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0746 - accuracy: 0.3753 - val_loss: 0.0726 - val_accuracy: 0.3846\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0742 - accuracy: 0.3798 - val_loss: 0.0722 - val_accuracy: 0.3880\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0737 - accuracy: 0.3879 - val_loss: 0.0718 - val_accuracy: 0.3921\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0733 - accuracy: 0.3951 - val_loss: 0.0714 - val_accuracy: 0.3950\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0729 - accuracy: 0.3990 - val_loss: 0.0709 - val_accuracy: 0.3979\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0725 - accuracy: 0.4036 - val_loss: 0.0704 - val_accuracy: 0.4024\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0720 - accuracy: 0.4099 - val_loss: 0.0697 - val_accuracy: 0.4072\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0715 - accuracy: 0.4145 - val_loss: 0.0691 - val_accuracy: 0.4132\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0710 - accuracy: 0.4209 - val_loss: 0.0684 - val_accuracy: 0.4232\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0703 - accuracy: 0.4275 - val_loss: 0.0675 - val_accuracy: 0.4331\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0698 - accuracy: 0.4342 - val_loss: 0.0666 - val_accuracy: 0.4414\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0692 - accuracy: 0.4395 - val_loss: 0.0657 - val_accuracy: 0.4519\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0685 - accuracy: 0.4439 - val_loss: 0.0646 - val_accuracy: 0.4634\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0677 - accuracy: 0.4531 - val_loss: 0.0634 - val_accuracy: 0.4751\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0667 - accuracy: 0.4604 - val_loss: 0.0620 - val_accuracy: 0.4882\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0658 - accuracy: 0.4729 - val_loss: 0.0605 - val_accuracy: 0.5047\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0648 - accuracy: 0.4795 - val_loss: 0.0587 - val_accuracy: 0.5199\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0635 - accuracy: 0.4900 - val_loss: 0.0569 - val_accuracy: 0.5364\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0622 - accuracy: 0.5081 - val_loss: 0.0549 - val_accuracy: 0.5614\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0605 - accuracy: 0.5259 - val_loss: 0.0527 - val_accuracy: 0.6081\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0587 - accuracy: 0.5442 - val_loss: 0.0503 - val_accuracy: 0.6569\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0569 - accuracy: 0.5631 - val_loss: 0.0477 - val_accuracy: 0.6857\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0552 - accuracy: 0.5771 - val_loss: 0.0456 - val_accuracy: 0.6987\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0533 - accuracy: 0.5926 - val_loss: 0.0437 - val_accuracy: 0.7065\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0519 - accuracy: 0.6057 - val_loss: 0.0421 - val_accuracy: 0.7128\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0502 - accuracy: 0.6195 - val_loss: 0.0407 - val_accuracy: 0.7226\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0487 - accuracy: 0.6350 - val_loss: 0.0393 - val_accuracy: 0.7328\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0474 - accuracy: 0.6467 - val_loss: 0.0381 - val_accuracy: 0.7427\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0463 - accuracy: 0.6596 - val_loss: 0.0368 - val_accuracy: 0.7518\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0453 - accuracy: 0.6671 - val_loss: 0.0352 - val_accuracy: 0.7668\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0440 - accuracy: 0.6810 - val_loss: 0.0340 - val_accuracy: 0.7751\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0431 - accuracy: 0.6920 - val_loss: 0.0329 - val_accuracy: 0.7831\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0419 - accuracy: 0.7028 - val_loss: 0.0317 - val_accuracy: 0.7940\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0407 - accuracy: 0.7131 - val_loss: 0.0306 - val_accuracy: 0.8002\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0396 - accuracy: 0.7238 - val_loss: 0.0294 - val_accuracy: 0.8076\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0386 - accuracy: 0.7314 - val_loss: 0.0284 - val_accuracy: 0.8142\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0377 - accuracy: 0.7392 - val_loss: 0.0272 - val_accuracy: 0.8227\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0369 - accuracy: 0.7471 - val_loss: 0.0262 - val_accuracy: 0.8285\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0357 - accuracy: 0.7549 - val_loss: 0.0253 - val_accuracy: 0.8346\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0349 - accuracy: 0.7641 - val_loss: 0.0242 - val_accuracy: 0.8414\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0340 - accuracy: 0.7708 - val_loss: 0.0233 - val_accuracy: 0.8457\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0332 - accuracy: 0.7760 - val_loss: 0.0223 - val_accuracy: 0.8504\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0319 - accuracy: 0.7851 - val_loss: 0.0214 - val_accuracy: 0.8577\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0311 - accuracy: 0.7925 - val_loss: 0.0207 - val_accuracy: 0.8607\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0302 - accuracy: 0.7975 - val_loss: 0.0198 - val_accuracy: 0.8662\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0291 - accuracy: 0.8059 - val_loss: 0.0191 - val_accuracy: 0.8722\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0283 - accuracy: 0.8115 - val_loss: 0.0183 - val_accuracy: 0.8785\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0275 - accuracy: 0.8182 - val_loss: 0.0179 - val_accuracy: 0.8818\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0267 - accuracy: 0.8229 - val_loss: 0.0170 - val_accuracy: 0.8870\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0262 - accuracy: 0.8259 - val_loss: 0.0165 - val_accuracy: 0.8912\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0252 - accuracy: 0.8345 - val_loss: 0.0161 - val_accuracy: 0.8941\n",
            "Accuracy for  100  epochs:\n",
            "Test loss: 0.016108817819645627\n",
            "Test accuracy: 0.89410001039505 \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TskdQAXHCDSE",
        "colab_type": "code",
        "outputId": "fe85b512-c00e-4d24-fd7c-6d6c914b4d36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Write your answer in here\n",
        "\n",
        "model = make_model(8, 256, 'relu')\n",
        "history = model.fit(x_train, y_train, batch_size = 64, epochs = 200, validation_data  =(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Accuracy for ', 200, ' epochs:')\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1], '\\n\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=784, activation=\"relu\", units=256)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0900 - accuracy: 0.1066 - val_loss: 0.0899 - val_accuracy: 0.1030\n",
            "Epoch 2/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0900 - accuracy: 0.1091 - val_loss: 0.0899 - val_accuracy: 0.1010\n",
            "Epoch 3/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0900 - accuracy: 0.1107 - val_loss: 0.0899 - val_accuracy: 0.1005\n",
            "Epoch 4/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0899 - accuracy: 0.1138 - val_loss: 0.0899 - val_accuracy: 0.1009\n",
            "Epoch 5/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0899 - accuracy: 0.1138 - val_loss: 0.0898 - val_accuracy: 0.1029\n",
            "Epoch 6/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0899 - accuracy: 0.1169 - val_loss: 0.0898 - val_accuracy: 0.1059\n",
            "Epoch 7/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0898 - accuracy: 0.1187 - val_loss: 0.0897 - val_accuracy: 0.1072\n",
            "Epoch 8/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0898 - accuracy: 0.1203 - val_loss: 0.0897 - val_accuracy: 0.1077\n",
            "Epoch 9/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0898 - accuracy: 0.1198 - val_loss: 0.0896 - val_accuracy: 0.1093\n",
            "Epoch 10/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0897 - accuracy: 0.1211 - val_loss: 0.0896 - val_accuracy: 0.1126\n",
            "Epoch 11/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0897 - accuracy: 0.1230 - val_loss: 0.0895 - val_accuracy: 0.1144\n",
            "Epoch 12/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0896 - accuracy: 0.1226 - val_loss: 0.0894 - val_accuracy: 0.1149\n",
            "Epoch 13/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0895 - accuracy: 0.1203 - val_loss: 0.0893 - val_accuracy: 0.1157\n",
            "Epoch 14/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0894 - accuracy: 0.1175 - val_loss: 0.0891 - val_accuracy: 0.1154\n",
            "Epoch 15/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0893 - accuracy: 0.1149 - val_loss: 0.0889 - val_accuracy: 0.1150\n",
            "Epoch 16/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0890 - accuracy: 0.1121 - val_loss: 0.0886 - val_accuracy: 0.1153\n",
            "Epoch 17/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0887 - accuracy: 0.1103 - val_loss: 0.0881 - val_accuracy: 0.1197\n",
            "Epoch 18/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0883 - accuracy: 0.1119 - val_loss: 0.0874 - val_accuracy: 0.1349\n",
            "Epoch 19/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0877 - accuracy: 0.1193 - val_loss: 0.0865 - val_accuracy: 0.1729\n",
            "Epoch 20/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0870 - accuracy: 0.1338 - val_loss: 0.0857 - val_accuracy: 0.2170\n",
            "Epoch 21/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0864 - accuracy: 0.1578 - val_loss: 0.0849 - val_accuracy: 0.2316\n",
            "Epoch 22/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0857 - accuracy: 0.1793 - val_loss: 0.0842 - val_accuracy: 0.2295\n",
            "Epoch 23/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0851 - accuracy: 0.1984 - val_loss: 0.0836 - val_accuracy: 0.2252\n",
            "Epoch 24/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0846 - accuracy: 0.2112 - val_loss: 0.0832 - val_accuracy: 0.2221\n",
            "Epoch 25/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0842 - accuracy: 0.2200 - val_loss: 0.0829 - val_accuracy: 0.2213\n",
            "Epoch 26/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0838 - accuracy: 0.2240 - val_loss: 0.0826 - val_accuracy: 0.2199\n",
            "Epoch 27/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0835 - accuracy: 0.2281 - val_loss: 0.0824 - val_accuracy: 0.2182\n",
            "Epoch 28/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0832 - accuracy: 0.2317 - val_loss: 0.0823 - val_accuracy: 0.2174\n",
            "Epoch 29/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0830 - accuracy: 0.2327 - val_loss: 0.0821 - val_accuracy: 0.2179\n",
            "Epoch 30/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0828 - accuracy: 0.2350 - val_loss: 0.0820 - val_accuracy: 0.2186\n",
            "Epoch 31/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0826 - accuracy: 0.2366 - val_loss: 0.0819 - val_accuracy: 0.2184\n",
            "Epoch 32/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0825 - accuracy: 0.2393 - val_loss: 0.0818 - val_accuracy: 0.2181\n",
            "Epoch 33/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0824 - accuracy: 0.2412 - val_loss: 0.0817 - val_accuracy: 0.2183\n",
            "Epoch 34/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0823 - accuracy: 0.2416 - val_loss: 0.0816 - val_accuracy: 0.2186\n",
            "Epoch 35/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0822 - accuracy: 0.2439 - val_loss: 0.0816 - val_accuracy: 0.2186\n",
            "Epoch 36/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0820 - accuracy: 0.2458 - val_loss: 0.0815 - val_accuracy: 0.2191\n",
            "Epoch 37/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0819 - accuracy: 0.2491 - val_loss: 0.0814 - val_accuracy: 0.2198\n",
            "Epoch 38/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0818 - accuracy: 0.2529 - val_loss: 0.0813 - val_accuracy: 0.2207\n",
            "Epoch 39/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0817 - accuracy: 0.2555 - val_loss: 0.0812 - val_accuracy: 0.2214\n",
            "Epoch 40/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0816 - accuracy: 0.2589 - val_loss: 0.0812 - val_accuracy: 0.2233\n",
            "Epoch 41/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0815 - accuracy: 0.2628 - val_loss: 0.0811 - val_accuracy: 0.2254\n",
            "Epoch 42/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0814 - accuracy: 0.2677 - val_loss: 0.0810 - val_accuracy: 0.2280\n",
            "Epoch 43/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0813 - accuracy: 0.2693 - val_loss: 0.0809 - val_accuracy: 0.2309\n",
            "Epoch 44/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0812 - accuracy: 0.2736 - val_loss: 0.0808 - val_accuracy: 0.2355\n",
            "Epoch 45/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0811 - accuracy: 0.2759 - val_loss: 0.0807 - val_accuracy: 0.2412\n",
            "Epoch 46/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0810 - accuracy: 0.2794 - val_loss: 0.0805 - val_accuracy: 0.2478\n",
            "Epoch 47/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0809 - accuracy: 0.2844 - val_loss: 0.0804 - val_accuracy: 0.2557\n",
            "Epoch 48/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0807 - accuracy: 0.2847 - val_loss: 0.0802 - val_accuracy: 0.2629\n",
            "Epoch 49/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0806 - accuracy: 0.2874 - val_loss: 0.0800 - val_accuracy: 0.2679\n",
            "Epoch 50/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0804 - accuracy: 0.2896 - val_loss: 0.0798 - val_accuracy: 0.2761\n",
            "Epoch 51/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0802 - accuracy: 0.2886 - val_loss: 0.0795 - val_accuracy: 0.2829\n",
            "Epoch 52/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0800 - accuracy: 0.2880 - val_loss: 0.0792 - val_accuracy: 0.2875\n",
            "Epoch 53/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0797 - accuracy: 0.2904 - val_loss: 0.0789 - val_accuracy: 0.2933\n",
            "Epoch 54/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0794 - accuracy: 0.2908 - val_loss: 0.0784 - val_accuracy: 0.2962\n",
            "Epoch 55/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0791 - accuracy: 0.2910 - val_loss: 0.0780 - val_accuracy: 0.2975\n",
            "Epoch 56/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0787 - accuracy: 0.2910 - val_loss: 0.0775 - val_accuracy: 0.2991\n",
            "Epoch 57/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0784 - accuracy: 0.2927 - val_loss: 0.0769 - val_accuracy: 0.2996\n",
            "Epoch 58/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0779 - accuracy: 0.2953 - val_loss: 0.0764 - val_accuracy: 0.3003\n",
            "Epoch 59/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0775 - accuracy: 0.2986 - val_loss: 0.0758 - val_accuracy: 0.3021\n",
            "Epoch 60/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0769 - accuracy: 0.3006 - val_loss: 0.0751 - val_accuracy: 0.3057\n",
            "Epoch 61/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0764 - accuracy: 0.3055 - val_loss: 0.0745 - val_accuracy: 0.3115\n",
            "Epoch 62/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0759 - accuracy: 0.3121 - val_loss: 0.0739 - val_accuracy: 0.3220\n",
            "Epoch 63/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0753 - accuracy: 0.3191 - val_loss: 0.0732 - val_accuracy: 0.3342\n",
            "Epoch 64/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0748 - accuracy: 0.3276 - val_loss: 0.0726 - val_accuracy: 0.3502\n",
            "Epoch 65/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0743 - accuracy: 0.3408 - val_loss: 0.0719 - val_accuracy: 0.3695\n",
            "Epoch 66/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0737 - accuracy: 0.3499 - val_loss: 0.0712 - val_accuracy: 0.3877\n",
            "Epoch 67/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0732 - accuracy: 0.3617 - val_loss: 0.0705 - val_accuracy: 0.4072\n",
            "Epoch 68/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0726 - accuracy: 0.3761 - val_loss: 0.0697 - val_accuracy: 0.4280\n",
            "Epoch 69/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0720 - accuracy: 0.3843 - val_loss: 0.0689 - val_accuracy: 0.4450\n",
            "Epoch 70/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0713 - accuracy: 0.3962 - val_loss: 0.0679 - val_accuracy: 0.4629\n",
            "Epoch 71/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0706 - accuracy: 0.4085 - val_loss: 0.0666 - val_accuracy: 0.4754\n",
            "Epoch 72/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0698 - accuracy: 0.4202 - val_loss: 0.0653 - val_accuracy: 0.4843\n",
            "Epoch 73/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0687 - accuracy: 0.4312 - val_loss: 0.0635 - val_accuracy: 0.4937\n",
            "Epoch 74/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0673 - accuracy: 0.4447 - val_loss: 0.0613 - val_accuracy: 0.5043\n",
            "Epoch 75/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0657 - accuracy: 0.4568 - val_loss: 0.0590 - val_accuracy: 0.5102\n",
            "Epoch 76/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0640 - accuracy: 0.4672 - val_loss: 0.0571 - val_accuracy: 0.5150\n",
            "Epoch 77/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0624 - accuracy: 0.4792 - val_loss: 0.0554 - val_accuracy: 0.5202\n",
            "Epoch 78/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0610 - accuracy: 0.4899 - val_loss: 0.0541 - val_accuracy: 0.5282\n",
            "Epoch 79/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0596 - accuracy: 0.5049 - val_loss: 0.0526 - val_accuracy: 0.5395\n",
            "Epoch 80/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0583 - accuracy: 0.5182 - val_loss: 0.0511 - val_accuracy: 0.5553\n",
            "Epoch 81/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0571 - accuracy: 0.5335 - val_loss: 0.0495 - val_accuracy: 0.5828\n",
            "Epoch 82/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0556 - accuracy: 0.5521 - val_loss: 0.0478 - val_accuracy: 0.6103\n",
            "Epoch 83/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0540 - accuracy: 0.5706 - val_loss: 0.0461 - val_accuracy: 0.6349\n",
            "Epoch 84/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0527 - accuracy: 0.5866 - val_loss: 0.0446 - val_accuracy: 0.6467\n",
            "Epoch 85/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0513 - accuracy: 0.6002 - val_loss: 0.0433 - val_accuracy: 0.6581\n",
            "Epoch 86/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0500 - accuracy: 0.6125 - val_loss: 0.0421 - val_accuracy: 0.6761\n",
            "Epoch 87/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0489 - accuracy: 0.6216 - val_loss: 0.0411 - val_accuracy: 0.6934\n",
            "Epoch 88/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0478 - accuracy: 0.6336 - val_loss: 0.0402 - val_accuracy: 0.7087\n",
            "Epoch 89/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0469 - accuracy: 0.6468 - val_loss: 0.0394 - val_accuracy: 0.7248\n",
            "Epoch 90/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0459 - accuracy: 0.6585 - val_loss: 0.0384 - val_accuracy: 0.7394\n",
            "Epoch 91/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0450 - accuracy: 0.6686 - val_loss: 0.0374 - val_accuracy: 0.7528\n",
            "Epoch 92/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0441 - accuracy: 0.6762 - val_loss: 0.0364 - val_accuracy: 0.7555\n",
            "Epoch 93/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0431 - accuracy: 0.6887 - val_loss: 0.0353 - val_accuracy: 0.7635\n",
            "Epoch 94/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0421 - accuracy: 0.6994 - val_loss: 0.0341 - val_accuracy: 0.7711\n",
            "Epoch 95/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0411 - accuracy: 0.7090 - val_loss: 0.0330 - val_accuracy: 0.7807\n",
            "Epoch 96/200\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0401 - accuracy: 0.7182 - val_loss: 0.0318 - val_accuracy: 0.7921\n",
            "Epoch 97/200\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0390 - accuracy: 0.7290 - val_loss: 0.0306 - val_accuracy: 0.8043\n",
            "Epoch 98/200\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0381 - accuracy: 0.7370 - val_loss: 0.0294 - val_accuracy: 0.8151\n",
            "Epoch 99/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0371 - accuracy: 0.7441 - val_loss: 0.0281 - val_accuracy: 0.8263\n",
            "Epoch 100/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0360 - accuracy: 0.7556 - val_loss: 0.0268 - val_accuracy: 0.8350\n",
            "Epoch 101/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0350 - accuracy: 0.7638 - val_loss: 0.0256 - val_accuracy: 0.8419\n",
            "Epoch 102/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0340 - accuracy: 0.7719 - val_loss: 0.0244 - val_accuracy: 0.8486\n",
            "Epoch 103/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0329 - accuracy: 0.7798 - val_loss: 0.0231 - val_accuracy: 0.8591\n",
            "Epoch 104/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0316 - accuracy: 0.7912 - val_loss: 0.0217 - val_accuracy: 0.8679\n",
            "Epoch 105/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0308 - accuracy: 0.7966 - val_loss: 0.0205 - val_accuracy: 0.8728\n",
            "Epoch 106/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0295 - accuracy: 0.8064 - val_loss: 0.0196 - val_accuracy: 0.8753\n",
            "Epoch 107/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0285 - accuracy: 0.8126 - val_loss: 0.0186 - val_accuracy: 0.8819\n",
            "Epoch 108/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0275 - accuracy: 0.8198 - val_loss: 0.0179 - val_accuracy: 0.8852\n",
            "Epoch 109/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0267 - accuracy: 0.8258 - val_loss: 0.0173 - val_accuracy: 0.8886\n",
            "Epoch 110/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0260 - accuracy: 0.8301 - val_loss: 0.0166 - val_accuracy: 0.8943\n",
            "Epoch 111/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0252 - accuracy: 0.8354 - val_loss: 0.0159 - val_accuracy: 0.8973\n",
            "Epoch 112/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0243 - accuracy: 0.8415 - val_loss: 0.0156 - val_accuracy: 0.8991\n",
            "Epoch 113/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0236 - accuracy: 0.8465 - val_loss: 0.0151 - val_accuracy: 0.9015\n",
            "Epoch 114/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0232 - accuracy: 0.8491 - val_loss: 0.0147 - val_accuracy: 0.9037\n",
            "Epoch 115/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0225 - accuracy: 0.8536 - val_loss: 0.0143 - val_accuracy: 0.9061\n",
            "Epoch 116/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0218 - accuracy: 0.8594 - val_loss: 0.0141 - val_accuracy: 0.9069\n",
            "Epoch 117/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0214 - accuracy: 0.8620 - val_loss: 0.0138 - val_accuracy: 0.9088\n",
            "Epoch 118/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0212 - accuracy: 0.8630 - val_loss: 0.0134 - val_accuracy: 0.9114\n",
            "Epoch 119/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0205 - accuracy: 0.8666 - val_loss: 0.0131 - val_accuracy: 0.9138\n",
            "Epoch 120/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0200 - accuracy: 0.8711 - val_loss: 0.0130 - val_accuracy: 0.9140\n",
            "Epoch 121/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0196 - accuracy: 0.8732 - val_loss: 0.0127 - val_accuracy: 0.9168\n",
            "Epoch 122/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0194 - accuracy: 0.8755 - val_loss: 0.0125 - val_accuracy: 0.9177\n",
            "Epoch 123/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0189 - accuracy: 0.8782 - val_loss: 0.0123 - val_accuracy: 0.9192\n",
            "Epoch 124/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0187 - accuracy: 0.8798 - val_loss: 0.0122 - val_accuracy: 0.9211\n",
            "Epoch 125/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0182 - accuracy: 0.8834 - val_loss: 0.0119 - val_accuracy: 0.9224\n",
            "Epoch 126/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0180 - accuracy: 0.8842 - val_loss: 0.0117 - val_accuracy: 0.9234\n",
            "Epoch 127/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0176 - accuracy: 0.8866 - val_loss: 0.0116 - val_accuracy: 0.9239\n",
            "Epoch 128/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0175 - accuracy: 0.8871 - val_loss: 0.0115 - val_accuracy: 0.9255\n",
            "Epoch 129/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0173 - accuracy: 0.8900 - val_loss: 0.0114 - val_accuracy: 0.9258\n",
            "Epoch 130/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0169 - accuracy: 0.8911 - val_loss: 0.0112 - val_accuracy: 0.9273\n",
            "Epoch 131/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0164 - accuracy: 0.8942 - val_loss: 0.0111 - val_accuracy: 0.9278\n",
            "Epoch 132/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0164 - accuracy: 0.8944 - val_loss: 0.0109 - val_accuracy: 0.9294\n",
            "Epoch 133/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0162 - accuracy: 0.8966 - val_loss: 0.0108 - val_accuracy: 0.9294\n",
            "Epoch 134/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0161 - accuracy: 0.8960 - val_loss: 0.0108 - val_accuracy: 0.9301\n",
            "Epoch 135/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0158 - accuracy: 0.8990 - val_loss: 0.0106 - val_accuracy: 0.9319\n",
            "Epoch 136/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0156 - accuracy: 0.9007 - val_loss: 0.0105 - val_accuracy: 0.9320\n",
            "Epoch 137/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0155 - accuracy: 0.9008 - val_loss: 0.0104 - val_accuracy: 0.9318\n",
            "Epoch 138/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0154 - accuracy: 0.9018 - val_loss: 0.0103 - val_accuracy: 0.9329\n",
            "Epoch 139/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0151 - accuracy: 0.9040 - val_loss: 0.0102 - val_accuracy: 0.9340\n",
            "Epoch 140/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0151 - accuracy: 0.9035 - val_loss: 0.0101 - val_accuracy: 0.9347\n",
            "Epoch 141/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0147 - accuracy: 0.9060 - val_loss: 0.0100 - val_accuracy: 0.9345\n",
            "Epoch 142/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0146 - accuracy: 0.9061 - val_loss: 0.0100 - val_accuracy: 0.9352\n",
            "Epoch 143/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0145 - accuracy: 0.9068 - val_loss: 0.0098 - val_accuracy: 0.9366\n",
            "Epoch 144/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0143 - accuracy: 0.9081 - val_loss: 0.0098 - val_accuracy: 0.9363\n",
            "Epoch 145/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0142 - accuracy: 0.9092 - val_loss: 0.0097 - val_accuracy: 0.9371\n",
            "Epoch 146/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0140 - accuracy: 0.9099 - val_loss: 0.0096 - val_accuracy: 0.9372\n",
            "Epoch 147/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0138 - accuracy: 0.9121 - val_loss: 0.0096 - val_accuracy: 0.9378\n",
            "Epoch 148/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0136 - accuracy: 0.9126 - val_loss: 0.0095 - val_accuracy: 0.9386\n",
            "Epoch 149/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0135 - accuracy: 0.9134 - val_loss: 0.0094 - val_accuracy: 0.9395\n",
            "Epoch 150/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0134 - accuracy: 0.9147 - val_loss: 0.0093 - val_accuracy: 0.9402\n",
            "Epoch 151/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0133 - accuracy: 0.9153 - val_loss: 0.0092 - val_accuracy: 0.9408\n",
            "Epoch 152/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0131 - accuracy: 0.9164 - val_loss: 0.0092 - val_accuracy: 0.9406\n",
            "Epoch 153/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0130 - accuracy: 0.9172 - val_loss: 0.0092 - val_accuracy: 0.9408\n",
            "Epoch 154/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0127 - accuracy: 0.9189 - val_loss: 0.0091 - val_accuracy: 0.9419\n",
            "Epoch 155/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0127 - accuracy: 0.9180 - val_loss: 0.0090 - val_accuracy: 0.9426\n",
            "Epoch 156/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0127 - accuracy: 0.9191 - val_loss: 0.0090 - val_accuracy: 0.9425\n",
            "Epoch 157/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0126 - accuracy: 0.9198 - val_loss: 0.0089 - val_accuracy: 0.9430\n",
            "Epoch 158/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0125 - accuracy: 0.9199 - val_loss: 0.0089 - val_accuracy: 0.9431\n",
            "Epoch 159/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0123 - accuracy: 0.9215 - val_loss: 0.0088 - val_accuracy: 0.9437\n",
            "Epoch 160/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0125 - accuracy: 0.9192 - val_loss: 0.0088 - val_accuracy: 0.9441\n",
            "Epoch 161/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0122 - accuracy: 0.9224 - val_loss: 0.0087 - val_accuracy: 0.9442\n",
            "Epoch 162/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0121 - accuracy: 0.9222 - val_loss: 0.0086 - val_accuracy: 0.9443\n",
            "Epoch 163/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0121 - accuracy: 0.9226 - val_loss: 0.0086 - val_accuracy: 0.9443\n",
            "Epoch 164/200\n",
            "60000/60000 [==============================] - 4s 58us/step - loss: 0.0119 - accuracy: 0.9232 - val_loss: 0.0085 - val_accuracy: 0.9455\n",
            "Epoch 165/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0119 - accuracy: 0.9241 - val_loss: 0.0085 - val_accuracy: 0.9459\n",
            "Epoch 166/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0117 - accuracy: 0.9256 - val_loss: 0.0085 - val_accuracy: 0.9461\n",
            "Epoch 167/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0117 - accuracy: 0.9247 - val_loss: 0.0084 - val_accuracy: 0.9462\n",
            "Epoch 168/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0115 - accuracy: 0.9265 - val_loss: 0.0084 - val_accuracy: 0.9468\n",
            "Epoch 169/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0113 - accuracy: 0.9276 - val_loss: 0.0084 - val_accuracy: 0.9468\n",
            "Epoch 170/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0115 - accuracy: 0.9269 - val_loss: 0.0082 - val_accuracy: 0.9476\n",
            "Epoch 171/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0114 - accuracy: 0.9274 - val_loss: 0.0082 - val_accuracy: 0.9476\n",
            "Epoch 172/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0112 - accuracy: 0.9288 - val_loss: 0.0082 - val_accuracy: 0.9477\n",
            "Epoch 173/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0111 - accuracy: 0.9284 - val_loss: 0.0081 - val_accuracy: 0.9478\n",
            "Epoch 174/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0111 - accuracy: 0.9292 - val_loss: 0.0082 - val_accuracy: 0.9476\n",
            "Epoch 175/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0110 - accuracy: 0.9287 - val_loss: 0.0081 - val_accuracy: 0.9485\n",
            "Epoch 176/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0110 - accuracy: 0.9297 - val_loss: 0.0081 - val_accuracy: 0.9485\n",
            "Epoch 177/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0109 - accuracy: 0.9307 - val_loss: 0.0080 - val_accuracy: 0.9488\n",
            "Epoch 178/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0108 - accuracy: 0.9308 - val_loss: 0.0079 - val_accuracy: 0.9496\n",
            "Epoch 179/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0107 - accuracy: 0.9316 - val_loss: 0.0079 - val_accuracy: 0.9497\n",
            "Epoch 180/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0106 - accuracy: 0.9324 - val_loss: 0.0079 - val_accuracy: 0.9506\n",
            "Epoch 181/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0105 - accuracy: 0.9336 - val_loss: 0.0078 - val_accuracy: 0.9507\n",
            "Epoch 182/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0105 - accuracy: 0.9331 - val_loss: 0.0078 - val_accuracy: 0.9506\n",
            "Epoch 183/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0105 - accuracy: 0.9333 - val_loss: 0.0078 - val_accuracy: 0.9509\n",
            "Epoch 184/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0104 - accuracy: 0.9348 - val_loss: 0.0077 - val_accuracy: 0.9513\n",
            "Epoch 185/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0103 - accuracy: 0.9344 - val_loss: 0.0076 - val_accuracy: 0.9520\n",
            "Epoch 186/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0103 - accuracy: 0.9350 - val_loss: 0.0076 - val_accuracy: 0.9516\n",
            "Epoch 187/200\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0101 - accuracy: 0.9352 - val_loss: 0.0076 - val_accuracy: 0.9521\n",
            "Epoch 188/200\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0102 - accuracy: 0.9352 - val_loss: 0.0076 - val_accuracy: 0.9530\n",
            "Epoch 189/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0102 - accuracy: 0.9356 - val_loss: 0.0075 - val_accuracy: 0.9529\n",
            "Epoch 190/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0102 - accuracy: 0.9349 - val_loss: 0.0075 - val_accuracy: 0.9523\n",
            "Epoch 191/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0100 - accuracy: 0.9367 - val_loss: 0.0075 - val_accuracy: 0.9527\n",
            "Epoch 192/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0100 - accuracy: 0.9362 - val_loss: 0.0074 - val_accuracy: 0.9526\n",
            "Epoch 193/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0101 - accuracy: 0.9358 - val_loss: 0.0074 - val_accuracy: 0.9527\n",
            "Epoch 194/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0100 - accuracy: 0.9363 - val_loss: 0.0074 - val_accuracy: 0.9529\n",
            "Epoch 195/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0097 - accuracy: 0.9384 - val_loss: 0.0074 - val_accuracy: 0.9532\n",
            "Epoch 196/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0097 - accuracy: 0.9386 - val_loss: 0.0073 - val_accuracy: 0.9536\n",
            "Epoch 197/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0097 - accuracy: 0.9377 - val_loss: 0.0073 - val_accuracy: 0.9536\n",
            "Epoch 198/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0096 - accuracy: 0.9385 - val_loss: 0.0073 - val_accuracy: 0.9536\n",
            "Epoch 199/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0096 - accuracy: 0.9400 - val_loss: 0.0073 - val_accuracy: 0.9538\n",
            "Epoch 200/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0094 - accuracy: 0.9406 - val_loss: 0.0073 - val_accuracy: 0.9534\n",
            "Accuracy for  200  epochs:\n",
            "Test loss: 0.007255697175024216\n",
            "Test accuracy: 0.9534000158309937 \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFaT0oJmDKrw",
        "colab_type": "code",
        "outputId": "139c8e44-69f6-4167-a118-170c481b9399",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Write your answer in here\n",
        "\n",
        "model = make_model(8, 256, 'relu')\n",
        "history = model.fit(x_train, y_train, batch_size = 64, epochs = 300, validation_data  =(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Accuracy for ', 300, ' epochs:')\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1], '\\n\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=784, activation=\"relu\", units=256)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/300\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0900 - accuracy: 0.1029 - val_loss: 0.0899 - val_accuracy: 0.1218\n",
            "Epoch 2/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0900 - accuracy: 0.1047 - val_loss: 0.0899 - val_accuracy: 0.1458\n",
            "Epoch 3/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0900 - accuracy: 0.1080 - val_loss: 0.0899 - val_accuracy: 0.1740\n",
            "Epoch 4/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0900 - accuracy: 0.1058 - val_loss: 0.0899 - val_accuracy: 0.1953\n",
            "Epoch 5/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0899 - accuracy: 0.1098 - val_loss: 0.0899 - val_accuracy: 0.2074\n",
            "Epoch 6/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0899 - accuracy: 0.1168 - val_loss: 0.0898 - val_accuracy: 0.2152\n",
            "Epoch 7/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0899 - accuracy: 0.1149 - val_loss: 0.0898 - val_accuracy: 0.2215\n",
            "Epoch 8/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0899 - accuracy: 0.1195 - val_loss: 0.0898 - val_accuracy: 0.2255\n",
            "Epoch 9/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0899 - accuracy: 0.1196 - val_loss: 0.0898 - val_accuracy: 0.2285\n",
            "Epoch 10/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0898 - accuracy: 0.1217 - val_loss: 0.0897 - val_accuracy: 0.2279\n",
            "Epoch 11/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0898 - accuracy: 0.1275 - val_loss: 0.0897 - val_accuracy: 0.2288\n",
            "Epoch 12/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0898 - accuracy: 0.1304 - val_loss: 0.0896 - val_accuracy: 0.2253\n",
            "Epoch 13/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0897 - accuracy: 0.1316 - val_loss: 0.0896 - val_accuracy: 0.2226\n",
            "Epoch 14/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0897 - accuracy: 0.1352 - val_loss: 0.0895 - val_accuracy: 0.2189\n",
            "Epoch 15/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0897 - accuracy: 0.1362 - val_loss: 0.0895 - val_accuracy: 0.2168\n",
            "Epoch 16/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0896 - accuracy: 0.1387 - val_loss: 0.0894 - val_accuracy: 0.2156\n",
            "Epoch 17/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0896 - accuracy: 0.1423 - val_loss: 0.0893 - val_accuracy: 0.2144\n",
            "Epoch 18/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0895 - accuracy: 0.1404 - val_loss: 0.0892 - val_accuracy: 0.2137\n",
            "Epoch 19/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0894 - accuracy: 0.1418 - val_loss: 0.0891 - val_accuracy: 0.2113\n",
            "Epoch 20/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0893 - accuracy: 0.1403 - val_loss: 0.0889 - val_accuracy: 0.2091\n",
            "Epoch 21/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0891 - accuracy: 0.1383 - val_loss: 0.0887 - val_accuracy: 0.2071\n",
            "Epoch 22/300\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0889 - accuracy: 0.1359 - val_loss: 0.0883 - val_accuracy: 0.2044\n",
            "Epoch 23/300\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0886 - accuracy: 0.1335 - val_loss: 0.0878 - val_accuracy: 0.2032\n",
            "Epoch 24/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0881 - accuracy: 0.1368 - val_loss: 0.0872 - val_accuracy: 0.2056\n",
            "Epoch 25/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0876 - accuracy: 0.1481 - val_loss: 0.0863 - val_accuracy: 0.2092\n",
            "Epoch 26/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0869 - accuracy: 0.1686 - val_loss: 0.0853 - val_accuracy: 0.2104\n",
            "Epoch 27/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0861 - accuracy: 0.1916 - val_loss: 0.0845 - val_accuracy: 0.2107\n",
            "Epoch 28/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0855 - accuracy: 0.2092 - val_loss: 0.0838 - val_accuracy: 0.2122\n",
            "Epoch 29/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0848 - accuracy: 0.2227 - val_loss: 0.0832 - val_accuracy: 0.2134\n",
            "Epoch 30/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0842 - accuracy: 0.2329 - val_loss: 0.0828 - val_accuracy: 0.2168\n",
            "Epoch 31/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0837 - accuracy: 0.2364 - val_loss: 0.0825 - val_accuracy: 0.2220\n",
            "Epoch 32/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0834 - accuracy: 0.2430 - val_loss: 0.0822 - val_accuracy: 0.2228\n",
            "Epoch 33/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0831 - accuracy: 0.2474 - val_loss: 0.0820 - val_accuracy: 0.2261\n",
            "Epoch 34/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0828 - accuracy: 0.2538 - val_loss: 0.0818 - val_accuracy: 0.2284\n",
            "Epoch 35/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0826 - accuracy: 0.2567 - val_loss: 0.0816 - val_accuracy: 0.2296\n",
            "Epoch 36/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0824 - accuracy: 0.2603 - val_loss: 0.0815 - val_accuracy: 0.2313\n",
            "Epoch 37/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0821 - accuracy: 0.2678 - val_loss: 0.0813 - val_accuracy: 0.2359\n",
            "Epoch 38/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0820 - accuracy: 0.2724 - val_loss: 0.0811 - val_accuracy: 0.2411\n",
            "Epoch 39/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0818 - accuracy: 0.2788 - val_loss: 0.0809 - val_accuracy: 0.2487\n",
            "Epoch 40/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0816 - accuracy: 0.2843 - val_loss: 0.0807 - val_accuracy: 0.2572\n",
            "Epoch 41/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0814 - accuracy: 0.2906 - val_loss: 0.0805 - val_accuracy: 0.2698\n",
            "Epoch 42/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0812 - accuracy: 0.2973 - val_loss: 0.0802 - val_accuracy: 0.2867\n",
            "Epoch 43/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0809 - accuracy: 0.3031 - val_loss: 0.0799 - val_accuracy: 0.3004\n",
            "Epoch 44/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0807 - accuracy: 0.3059 - val_loss: 0.0796 - val_accuracy: 0.3141\n",
            "Epoch 45/300\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0805 - accuracy: 0.3136 - val_loss: 0.0793 - val_accuracy: 0.3319\n",
            "Epoch 46/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0802 - accuracy: 0.3176 - val_loss: 0.0789 - val_accuracy: 0.3535\n",
            "Epoch 47/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0799 - accuracy: 0.3225 - val_loss: 0.0784 - val_accuracy: 0.3755\n",
            "Epoch 48/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0795 - accuracy: 0.3292 - val_loss: 0.0778 - val_accuracy: 0.3984\n",
            "Epoch 49/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0792 - accuracy: 0.3367 - val_loss: 0.0772 - val_accuracy: 0.4186\n",
            "Epoch 50/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0787 - accuracy: 0.3451 - val_loss: 0.0764 - val_accuracy: 0.4289\n",
            "Epoch 51/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0781 - accuracy: 0.3519 - val_loss: 0.0754 - val_accuracy: 0.4233\n",
            "Epoch 52/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0775 - accuracy: 0.3592 - val_loss: 0.0742 - val_accuracy: 0.4193\n",
            "Epoch 53/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0766 - accuracy: 0.3697 - val_loss: 0.0728 - val_accuracy: 0.4164\n",
            "Epoch 54/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0755 - accuracy: 0.3787 - val_loss: 0.0711 - val_accuracy: 0.4195\n",
            "Epoch 55/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0744 - accuracy: 0.3918 - val_loss: 0.0695 - val_accuracy: 0.4227\n",
            "Epoch 56/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0730 - accuracy: 0.4016 - val_loss: 0.0680 - val_accuracy: 0.4349\n",
            "Epoch 57/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0719 - accuracy: 0.4093 - val_loss: 0.0666 - val_accuracy: 0.4490\n",
            "Epoch 58/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0708 - accuracy: 0.4214 - val_loss: 0.0655 - val_accuracy: 0.4604\n",
            "Epoch 59/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0697 - accuracy: 0.4326 - val_loss: 0.0643 - val_accuracy: 0.4738\n",
            "Epoch 60/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0686 - accuracy: 0.4459 - val_loss: 0.0632 - val_accuracy: 0.4901\n",
            "Epoch 61/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0676 - accuracy: 0.4559 - val_loss: 0.0620 - val_accuracy: 0.5042\n",
            "Epoch 62/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0667 - accuracy: 0.4685 - val_loss: 0.0609 - val_accuracy: 0.5155\n",
            "Epoch 63/300\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0656 - accuracy: 0.4823 - val_loss: 0.0595 - val_accuracy: 0.5298\n",
            "Epoch 64/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0644 - accuracy: 0.4943 - val_loss: 0.0580 - val_accuracy: 0.5408\n",
            "Epoch 65/300\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0634 - accuracy: 0.5067 - val_loss: 0.0565 - val_accuracy: 0.5550\n",
            "Epoch 66/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0621 - accuracy: 0.5216 - val_loss: 0.0550 - val_accuracy: 0.5632\n",
            "Epoch 67/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0608 - accuracy: 0.5341 - val_loss: 0.0532 - val_accuracy: 0.5809\n",
            "Epoch 68/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0596 - accuracy: 0.5478 - val_loss: 0.0515 - val_accuracy: 0.5960\n",
            "Epoch 69/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0582 - accuracy: 0.5652 - val_loss: 0.0501 - val_accuracy: 0.6068\n",
            "Epoch 70/300\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0566 - accuracy: 0.5825 - val_loss: 0.0483 - val_accuracy: 0.6237\n",
            "Epoch 71/300\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0552 - accuracy: 0.6003 - val_loss: 0.0465 - val_accuracy: 0.6550\n",
            "Epoch 72/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0537 - accuracy: 0.6182 - val_loss: 0.0446 - val_accuracy: 0.6826\n",
            "Epoch 73/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0521 - accuracy: 0.6319 - val_loss: 0.0424 - val_accuracy: 0.7043\n",
            "Epoch 74/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0501 - accuracy: 0.6473 - val_loss: 0.0401 - val_accuracy: 0.7265\n",
            "Epoch 75/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0483 - accuracy: 0.6600 - val_loss: 0.0376 - val_accuracy: 0.7434\n",
            "Epoch 76/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0468 - accuracy: 0.6678 - val_loss: 0.0354 - val_accuracy: 0.7592\n",
            "Epoch 77/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0448 - accuracy: 0.6829 - val_loss: 0.0334 - val_accuracy: 0.7705\n",
            "Epoch 78/300\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0433 - accuracy: 0.6936 - val_loss: 0.0317 - val_accuracy: 0.7834\n",
            "Epoch 79/300\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0418 - accuracy: 0.7057 - val_loss: 0.0302 - val_accuracy: 0.7943\n",
            "Epoch 80/300\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0403 - accuracy: 0.7180 - val_loss: 0.0286 - val_accuracy: 0.8098\n",
            "Epoch 81/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0391 - accuracy: 0.7265 - val_loss: 0.0275 - val_accuracy: 0.8174\n",
            "Epoch 82/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0379 - accuracy: 0.7346 - val_loss: 0.0261 - val_accuracy: 0.8300\n",
            "Epoch 83/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0363 - accuracy: 0.7492 - val_loss: 0.0250 - val_accuracy: 0.8375\n",
            "Epoch 84/300\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0353 - accuracy: 0.7581 - val_loss: 0.0237 - val_accuracy: 0.8469\n",
            "Epoch 85/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0342 - accuracy: 0.7682 - val_loss: 0.0225 - val_accuracy: 0.8556\n",
            "Epoch 86/300\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0331 - accuracy: 0.7771 - val_loss: 0.0215 - val_accuracy: 0.8627\n",
            "Epoch 87/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0319 - accuracy: 0.7864 - val_loss: 0.0205 - val_accuracy: 0.8690\n",
            "Epoch 88/300\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0309 - accuracy: 0.7932 - val_loss: 0.0196 - val_accuracy: 0.8736\n",
            "Epoch 89/300\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0300 - accuracy: 0.7998 - val_loss: 0.0189 - val_accuracy: 0.8770\n",
            "Epoch 90/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0290 - accuracy: 0.8077 - val_loss: 0.0183 - val_accuracy: 0.8825\n",
            "Epoch 91/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0280 - accuracy: 0.8146 - val_loss: 0.0177 - val_accuracy: 0.8849\n",
            "Epoch 92/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0274 - accuracy: 0.8191 - val_loss: 0.0171 - val_accuracy: 0.8884\n",
            "Epoch 93/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0265 - accuracy: 0.8254 - val_loss: 0.0167 - val_accuracy: 0.8907\n",
            "Epoch 94/300\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0258 - accuracy: 0.8310 - val_loss: 0.0162 - val_accuracy: 0.8935\n",
            "Epoch 95/300\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0253 - accuracy: 0.8331 - val_loss: 0.0159 - val_accuracy: 0.8943\n",
            "Epoch 96/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0244 - accuracy: 0.8415 - val_loss: 0.0156 - val_accuracy: 0.8969\n",
            "Epoch 97/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0240 - accuracy: 0.8425 - val_loss: 0.0152 - val_accuracy: 0.8993\n",
            "Epoch 98/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0233 - accuracy: 0.8475 - val_loss: 0.0150 - val_accuracy: 0.9011\n",
            "Epoch 99/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0229 - accuracy: 0.8508 - val_loss: 0.0147 - val_accuracy: 0.9030\n",
            "Epoch 100/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0224 - accuracy: 0.8543 - val_loss: 0.0144 - val_accuracy: 0.9044\n",
            "Epoch 101/300\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0218 - accuracy: 0.8584 - val_loss: 0.0142 - val_accuracy: 0.9058\n",
            "Epoch 102/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0215 - accuracy: 0.8582 - val_loss: 0.0140 - val_accuracy: 0.9075\n",
            "Epoch 103/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0211 - accuracy: 0.8634 - val_loss: 0.0138 - val_accuracy: 0.9077\n",
            "Epoch 104/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0208 - accuracy: 0.8658 - val_loss: 0.0136 - val_accuracy: 0.9097\n",
            "Epoch 105/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0205 - accuracy: 0.8667 - val_loss: 0.0135 - val_accuracy: 0.9089\n",
            "Epoch 106/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0200 - accuracy: 0.8703 - val_loss: 0.0132 - val_accuracy: 0.9106\n",
            "Epoch 107/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0196 - accuracy: 0.8733 - val_loss: 0.0131 - val_accuracy: 0.9131\n",
            "Epoch 108/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0194 - accuracy: 0.8752 - val_loss: 0.0130 - val_accuracy: 0.9133\n",
            "Epoch 109/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0191 - accuracy: 0.8774 - val_loss: 0.0128 - val_accuracy: 0.9150\n",
            "Epoch 110/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0189 - accuracy: 0.8780 - val_loss: 0.0126 - val_accuracy: 0.9159\n",
            "Epoch 111/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0184 - accuracy: 0.8813 - val_loss: 0.0124 - val_accuracy: 0.9171\n",
            "Epoch 112/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0182 - accuracy: 0.8828 - val_loss: 0.0123 - val_accuracy: 0.9183\n",
            "Epoch 113/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0179 - accuracy: 0.8849 - val_loss: 0.0121 - val_accuracy: 0.9199\n",
            "Epoch 114/300\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0178 - accuracy: 0.8857 - val_loss: 0.0120 - val_accuracy: 0.9200\n",
            "Epoch 115/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0174 - accuracy: 0.8877 - val_loss: 0.0119 - val_accuracy: 0.9223\n",
            "Epoch 116/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0173 - accuracy: 0.8886 - val_loss: 0.0118 - val_accuracy: 0.9228\n",
            "Epoch 117/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0173 - accuracy: 0.8891 - val_loss: 0.0116 - val_accuracy: 0.9238\n",
            "Epoch 118/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0170 - accuracy: 0.8906 - val_loss: 0.0115 - val_accuracy: 0.9234\n",
            "Epoch 119/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0168 - accuracy: 0.8918 - val_loss: 0.0113 - val_accuracy: 0.9246\n",
            "Epoch 120/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0164 - accuracy: 0.8949 - val_loss: 0.0113 - val_accuracy: 0.9256\n",
            "Epoch 121/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0164 - accuracy: 0.8949 - val_loss: 0.0112 - val_accuracy: 0.9256\n",
            "Epoch 122/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0162 - accuracy: 0.8967 - val_loss: 0.0110 - val_accuracy: 0.9269\n",
            "Epoch 123/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0160 - accuracy: 0.8968 - val_loss: 0.0109 - val_accuracy: 0.9272\n",
            "Epoch 124/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0158 - accuracy: 0.8988 - val_loss: 0.0108 - val_accuracy: 0.9285\n",
            "Epoch 125/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0157 - accuracy: 0.8998 - val_loss: 0.0108 - val_accuracy: 0.9295\n",
            "Epoch 126/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0156 - accuracy: 0.8996 - val_loss: 0.0106 - val_accuracy: 0.9302\n",
            "Epoch 127/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0153 - accuracy: 0.9020 - val_loss: 0.0105 - val_accuracy: 0.9311\n",
            "Epoch 128/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0150 - accuracy: 0.9046 - val_loss: 0.0104 - val_accuracy: 0.9314\n",
            "Epoch 129/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0151 - accuracy: 0.9034 - val_loss: 0.0103 - val_accuracy: 0.9331\n",
            "Epoch 130/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0148 - accuracy: 0.9050 - val_loss: 0.0103 - val_accuracy: 0.9333\n",
            "Epoch 131/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0147 - accuracy: 0.9064 - val_loss: 0.0101 - val_accuracy: 0.9346\n",
            "Epoch 132/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0145 - accuracy: 0.9071 - val_loss: 0.0100 - val_accuracy: 0.9348\n",
            "Epoch 133/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0145 - accuracy: 0.9071 - val_loss: 0.0099 - val_accuracy: 0.9363\n",
            "Epoch 134/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0144 - accuracy: 0.9072 - val_loss: 0.0099 - val_accuracy: 0.9361\n",
            "Epoch 135/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0141 - accuracy: 0.9093 - val_loss: 0.0098 - val_accuracy: 0.9373\n",
            "Epoch 136/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0141 - accuracy: 0.9113 - val_loss: 0.0097 - val_accuracy: 0.9373\n",
            "Epoch 137/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0140 - accuracy: 0.9114 - val_loss: 0.0097 - val_accuracy: 0.9374\n",
            "Epoch 138/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0138 - accuracy: 0.9123 - val_loss: 0.0096 - val_accuracy: 0.9380\n",
            "Epoch 139/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0138 - accuracy: 0.9118 - val_loss: 0.0095 - val_accuracy: 0.9379\n",
            "Epoch 140/300\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0136 - accuracy: 0.9128 - val_loss: 0.0094 - val_accuracy: 0.9385\n",
            "Epoch 141/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0134 - accuracy: 0.9141 - val_loss: 0.0093 - val_accuracy: 0.9394\n",
            "Epoch 142/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0130 - accuracy: 0.9169 - val_loss: 0.0093 - val_accuracy: 0.9401\n",
            "Epoch 143/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0132 - accuracy: 0.9156 - val_loss: 0.0092 - val_accuracy: 0.9407\n",
            "Epoch 144/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0132 - accuracy: 0.9161 - val_loss: 0.0091 - val_accuracy: 0.9408\n",
            "Epoch 145/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0132 - accuracy: 0.9155 - val_loss: 0.0091 - val_accuracy: 0.9412\n",
            "Epoch 146/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0130 - accuracy: 0.9173 - val_loss: 0.0090 - val_accuracy: 0.9423\n",
            "Epoch 147/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0128 - accuracy: 0.9182 - val_loss: 0.0090 - val_accuracy: 0.9429\n",
            "Epoch 148/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0129 - accuracy: 0.9186 - val_loss: 0.0089 - val_accuracy: 0.9433\n",
            "Epoch 149/300\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0128 - accuracy: 0.9182 - val_loss: 0.0089 - val_accuracy: 0.9428\n",
            "Epoch 150/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0125 - accuracy: 0.9204 - val_loss: 0.0088 - val_accuracy: 0.9436\n",
            "Epoch 151/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0124 - accuracy: 0.9210 - val_loss: 0.0088 - val_accuracy: 0.9438\n",
            "Epoch 152/300\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0124 - accuracy: 0.9204 - val_loss: 0.0087 - val_accuracy: 0.9441\n",
            "Epoch 153/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0123 - accuracy: 0.9219 - val_loss: 0.0087 - val_accuracy: 0.9443\n",
            "Epoch 154/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0122 - accuracy: 0.9222 - val_loss: 0.0086 - val_accuracy: 0.9447\n",
            "Epoch 155/300\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0120 - accuracy: 0.9240 - val_loss: 0.0086 - val_accuracy: 0.9450\n",
            "Epoch 156/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0120 - accuracy: 0.9239 - val_loss: 0.0085 - val_accuracy: 0.9449\n",
            "Epoch 157/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0119 - accuracy: 0.9236 - val_loss: 0.0084 - val_accuracy: 0.9467\n",
            "Epoch 158/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0118 - accuracy: 0.9245 - val_loss: 0.0084 - val_accuracy: 0.9462\n",
            "Epoch 159/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0117 - accuracy: 0.9259 - val_loss: 0.0083 - val_accuracy: 0.9465\n",
            "Epoch 160/300\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0117 - accuracy: 0.9263 - val_loss: 0.0083 - val_accuracy: 0.9466\n",
            "Epoch 161/300\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0116 - accuracy: 0.9265 - val_loss: 0.0082 - val_accuracy: 0.9471\n",
            "Epoch 162/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0115 - accuracy: 0.9261 - val_loss: 0.0082 - val_accuracy: 0.9471\n",
            "Epoch 163/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0114 - accuracy: 0.9286 - val_loss: 0.0082 - val_accuracy: 0.9473\n",
            "Epoch 164/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0114 - accuracy: 0.9276 - val_loss: 0.0081 - val_accuracy: 0.9480\n",
            "Epoch 165/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0114 - accuracy: 0.9279 - val_loss: 0.0080 - val_accuracy: 0.9482\n",
            "Epoch 166/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0112 - accuracy: 0.9290 - val_loss: 0.0081 - val_accuracy: 0.9489\n",
            "Epoch 167/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0111 - accuracy: 0.9293 - val_loss: 0.0080 - val_accuracy: 0.9487\n",
            "Epoch 168/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0111 - accuracy: 0.9301 - val_loss: 0.0080 - val_accuracy: 0.9493\n",
            "Epoch 169/300\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0111 - accuracy: 0.9291 - val_loss: 0.0079 - val_accuracy: 0.9491\n",
            "Epoch 170/300\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0109 - accuracy: 0.9308 - val_loss: 0.0079 - val_accuracy: 0.9491\n",
            "Epoch 171/300\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0108 - accuracy: 0.9317 - val_loss: 0.0079 - val_accuracy: 0.9495\n",
            "Epoch 172/300\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0108 - accuracy: 0.9311 - val_loss: 0.0079 - val_accuracy: 0.9499\n",
            "Epoch 173/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0108 - accuracy: 0.9320 - val_loss: 0.0078 - val_accuracy: 0.9510\n",
            "Epoch 174/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0107 - accuracy: 0.9323 - val_loss: 0.0078 - val_accuracy: 0.9506\n",
            "Epoch 175/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0107 - accuracy: 0.9325 - val_loss: 0.0077 - val_accuracy: 0.9512\n",
            "Epoch 176/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0106 - accuracy: 0.9326 - val_loss: 0.0077 - val_accuracy: 0.9511\n",
            "Epoch 177/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0106 - accuracy: 0.9326 - val_loss: 0.0076 - val_accuracy: 0.9518\n",
            "Epoch 178/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0106 - accuracy: 0.9320 - val_loss: 0.0076 - val_accuracy: 0.9517\n",
            "Epoch 179/300\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0104 - accuracy: 0.9343 - val_loss: 0.0075 - val_accuracy: 0.9520\n",
            "Epoch 180/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0103 - accuracy: 0.9351 - val_loss: 0.0075 - val_accuracy: 0.9524\n",
            "Epoch 181/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0104 - accuracy: 0.9343 - val_loss: 0.0075 - val_accuracy: 0.9530\n",
            "Epoch 182/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0102 - accuracy: 0.9353 - val_loss: 0.0075 - val_accuracy: 0.9533\n",
            "Epoch 183/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0103 - accuracy: 0.9352 - val_loss: 0.0075 - val_accuracy: 0.9527\n",
            "Epoch 184/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0101 - accuracy: 0.9356 - val_loss: 0.0074 - val_accuracy: 0.9527\n",
            "Epoch 185/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0100 - accuracy: 0.9368 - val_loss: 0.0074 - val_accuracy: 0.9531\n",
            "Epoch 186/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0100 - accuracy: 0.9369 - val_loss: 0.0073 - val_accuracy: 0.9543\n",
            "Epoch 187/300\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0100 - accuracy: 0.9366 - val_loss: 0.0073 - val_accuracy: 0.9542\n",
            "Epoch 188/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0099 - accuracy: 0.9373 - val_loss: 0.0073 - val_accuracy: 0.9542\n",
            "Epoch 189/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0100 - accuracy: 0.9373 - val_loss: 0.0072 - val_accuracy: 0.9548\n",
            "Epoch 190/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0100 - accuracy: 0.9364 - val_loss: 0.0072 - val_accuracy: 0.9543\n",
            "Epoch 191/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0097 - accuracy: 0.9391 - val_loss: 0.0072 - val_accuracy: 0.9545\n",
            "Epoch 192/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0096 - accuracy: 0.9393 - val_loss: 0.0071 - val_accuracy: 0.9549\n",
            "Epoch 193/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0095 - accuracy: 0.9403 - val_loss: 0.0072 - val_accuracy: 0.9544\n",
            "Epoch 194/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0095 - accuracy: 0.9400 - val_loss: 0.0071 - val_accuracy: 0.9552\n",
            "Epoch 195/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0096 - accuracy: 0.9397 - val_loss: 0.0071 - val_accuracy: 0.9549\n",
            "Epoch 196/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0095 - accuracy: 0.9397 - val_loss: 0.0070 - val_accuracy: 0.9561\n",
            "Epoch 197/300\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0095 - accuracy: 0.9393 - val_loss: 0.0070 - val_accuracy: 0.9561\n",
            "Epoch 198/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0094 - accuracy: 0.9415 - val_loss: 0.0070 - val_accuracy: 0.9555\n",
            "Epoch 199/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0093 - accuracy: 0.9417 - val_loss: 0.0070 - val_accuracy: 0.9561\n",
            "Epoch 200/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0093 - accuracy: 0.9414 - val_loss: 0.0069 - val_accuracy: 0.9565\n",
            "Epoch 201/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0093 - accuracy: 0.9412 - val_loss: 0.0069 - val_accuracy: 0.9568\n",
            "Epoch 202/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0092 - accuracy: 0.9423 - val_loss: 0.0069 - val_accuracy: 0.9568\n",
            "Epoch 203/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0091 - accuracy: 0.9427 - val_loss: 0.0068 - val_accuracy: 0.9570\n",
            "Epoch 204/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0092 - accuracy: 0.9422 - val_loss: 0.0068 - val_accuracy: 0.9569\n",
            "Epoch 205/300\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0091 - accuracy: 0.9421 - val_loss: 0.0068 - val_accuracy: 0.9572\n",
            "Epoch 206/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0091 - accuracy: 0.9427 - val_loss: 0.0068 - val_accuracy: 0.9576\n",
            "Epoch 207/300\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0089 - accuracy: 0.9440 - val_loss: 0.0067 - val_accuracy: 0.9569\n",
            "Epoch 208/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0089 - accuracy: 0.9438 - val_loss: 0.0067 - val_accuracy: 0.9576\n",
            "Epoch 209/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0088 - accuracy: 0.9449 - val_loss: 0.0067 - val_accuracy: 0.9577\n",
            "Epoch 210/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0088 - accuracy: 0.9443 - val_loss: 0.0067 - val_accuracy: 0.9580\n",
            "Epoch 211/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0088 - accuracy: 0.9448 - val_loss: 0.0067 - val_accuracy: 0.9579\n",
            "Epoch 212/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0088 - accuracy: 0.9453 - val_loss: 0.0066 - val_accuracy: 0.9577\n",
            "Epoch 213/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0088 - accuracy: 0.9448 - val_loss: 0.0066 - val_accuracy: 0.9581\n",
            "Epoch 214/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0087 - accuracy: 0.9449 - val_loss: 0.0066 - val_accuracy: 0.9580\n",
            "Epoch 215/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0087 - accuracy: 0.9448 - val_loss: 0.0066 - val_accuracy: 0.9583\n",
            "Epoch 216/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0086 - accuracy: 0.9462 - val_loss: 0.0065 - val_accuracy: 0.9589\n",
            "Epoch 217/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0086 - accuracy: 0.9460 - val_loss: 0.0065 - val_accuracy: 0.9591\n",
            "Epoch 218/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0086 - accuracy: 0.9461 - val_loss: 0.0065 - val_accuracy: 0.9598\n",
            "Epoch 219/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0085 - accuracy: 0.9462 - val_loss: 0.0065 - val_accuracy: 0.9591\n",
            "Epoch 220/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0085 - accuracy: 0.9467 - val_loss: 0.0065 - val_accuracy: 0.9593\n",
            "Epoch 221/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0086 - accuracy: 0.9453 - val_loss: 0.0064 - val_accuracy: 0.9592\n",
            "Epoch 222/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0084 - accuracy: 0.9471 - val_loss: 0.0064 - val_accuracy: 0.9602\n",
            "Epoch 223/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0083 - accuracy: 0.9483 - val_loss: 0.0063 - val_accuracy: 0.9605\n",
            "Epoch 224/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0084 - accuracy: 0.9467 - val_loss: 0.0063 - val_accuracy: 0.9606\n",
            "Epoch 225/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0083 - accuracy: 0.9480 - val_loss: 0.0063 - val_accuracy: 0.9604\n",
            "Epoch 226/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0083 - accuracy: 0.9467 - val_loss: 0.0063 - val_accuracy: 0.9598\n",
            "Epoch 227/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0082 - accuracy: 0.9484 - val_loss: 0.0063 - val_accuracy: 0.9606\n",
            "Epoch 228/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0082 - accuracy: 0.9485 - val_loss: 0.0063 - val_accuracy: 0.9603\n",
            "Epoch 229/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0082 - accuracy: 0.9486 - val_loss: 0.0063 - val_accuracy: 0.9605\n",
            "Epoch 230/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0082 - accuracy: 0.9477 - val_loss: 0.0062 - val_accuracy: 0.9613\n",
            "Epoch 231/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0081 - accuracy: 0.9497 - val_loss: 0.0062 - val_accuracy: 0.9618\n",
            "Epoch 232/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0081 - accuracy: 0.9495 - val_loss: 0.0062 - val_accuracy: 0.9613\n",
            "Epoch 233/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0080 - accuracy: 0.9491 - val_loss: 0.0062 - val_accuracy: 0.9611\n",
            "Epoch 234/300\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0080 - accuracy: 0.9494 - val_loss: 0.0062 - val_accuracy: 0.9614\n",
            "Epoch 235/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0080 - accuracy: 0.9503 - val_loss: 0.0061 - val_accuracy: 0.9614\n",
            "Epoch 236/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0078 - accuracy: 0.9509 - val_loss: 0.0061 - val_accuracy: 0.9616\n",
            "Epoch 237/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0079 - accuracy: 0.9504 - val_loss: 0.0061 - val_accuracy: 0.9616\n",
            "Epoch 238/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0079 - accuracy: 0.9513 - val_loss: 0.0061 - val_accuracy: 0.9617\n",
            "Epoch 239/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0078 - accuracy: 0.9505 - val_loss: 0.0061 - val_accuracy: 0.9621\n",
            "Epoch 240/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0079 - accuracy: 0.9506 - val_loss: 0.0061 - val_accuracy: 0.9619\n",
            "Epoch 241/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0077 - accuracy: 0.9524 - val_loss: 0.0061 - val_accuracy: 0.9621\n",
            "Epoch 242/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0076 - accuracy: 0.9522 - val_loss: 0.0060 - val_accuracy: 0.9622\n",
            "Epoch 243/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0077 - accuracy: 0.9524 - val_loss: 0.0060 - val_accuracy: 0.9618\n",
            "Epoch 244/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0077 - accuracy: 0.9512 - val_loss: 0.0060 - val_accuracy: 0.9627\n",
            "Epoch 245/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0077 - accuracy: 0.9517 - val_loss: 0.0060 - val_accuracy: 0.9624\n",
            "Epoch 246/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0076 - accuracy: 0.9528 - val_loss: 0.0060 - val_accuracy: 0.9623\n",
            "Epoch 247/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0075 - accuracy: 0.9532 - val_loss: 0.0060 - val_accuracy: 0.9626\n",
            "Epoch 248/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0075 - accuracy: 0.9533 - val_loss: 0.0060 - val_accuracy: 0.9627\n",
            "Epoch 249/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0076 - accuracy: 0.9521 - val_loss: 0.0060 - val_accuracy: 0.9627\n",
            "Epoch 250/300\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0074 - accuracy: 0.9537 - val_loss: 0.0059 - val_accuracy: 0.9637\n",
            "Epoch 251/300\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0074 - accuracy: 0.9536 - val_loss: 0.0059 - val_accuracy: 0.9628\n",
            "Epoch 252/300\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0074 - accuracy: 0.9538 - val_loss: 0.0059 - val_accuracy: 0.9633\n",
            "Epoch 253/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0074 - accuracy: 0.9536 - val_loss: 0.0058 - val_accuracy: 0.9633\n",
            "Epoch 254/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0074 - accuracy: 0.9539 - val_loss: 0.0058 - val_accuracy: 0.9633\n",
            "Epoch 255/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0072 - accuracy: 0.9552 - val_loss: 0.0058 - val_accuracy: 0.9634\n",
            "Epoch 256/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0074 - accuracy: 0.9531 - val_loss: 0.0058 - val_accuracy: 0.9634\n",
            "Epoch 257/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0074 - accuracy: 0.9531 - val_loss: 0.0058 - val_accuracy: 0.9634\n",
            "Epoch 258/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0073 - accuracy: 0.9542 - val_loss: 0.0058 - val_accuracy: 0.9635\n",
            "Epoch 259/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0073 - accuracy: 0.9540 - val_loss: 0.0058 - val_accuracy: 0.9636\n",
            "Epoch 260/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0072 - accuracy: 0.9552 - val_loss: 0.0058 - val_accuracy: 0.9641\n",
            "Epoch 261/300\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0071 - accuracy: 0.9554 - val_loss: 0.0057 - val_accuracy: 0.9640\n",
            "Epoch 262/300\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.0071 - accuracy: 0.9553 - val_loss: 0.0057 - val_accuracy: 0.9642\n",
            "Epoch 263/300\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0071 - accuracy: 0.9557 - val_loss: 0.0057 - val_accuracy: 0.9637\n",
            "Epoch 264/300\n",
            "60000/60000 [==============================] - 4s 58us/step - loss: 0.0071 - accuracy: 0.9560 - val_loss: 0.0057 - val_accuracy: 0.9645\n",
            "Epoch 265/300\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0071 - accuracy: 0.9554 - val_loss: 0.0057 - val_accuracy: 0.9644\n",
            "Epoch 266/300\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0071 - accuracy: 0.9557 - val_loss: 0.0057 - val_accuracy: 0.9646\n",
            "Epoch 267/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0070 - accuracy: 0.9560 - val_loss: 0.0057 - val_accuracy: 0.9646\n",
            "Epoch 268/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0070 - accuracy: 0.9561 - val_loss: 0.0056 - val_accuracy: 0.9652\n",
            "Epoch 269/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0071 - accuracy: 0.9562 - val_loss: 0.0056 - val_accuracy: 0.9651\n",
            "Epoch 270/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0070 - accuracy: 0.9560 - val_loss: 0.0056 - val_accuracy: 0.9653\n",
            "Epoch 271/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0069 - accuracy: 0.9570 - val_loss: 0.0056 - val_accuracy: 0.9656\n",
            "Epoch 272/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0070 - accuracy: 0.9562 - val_loss: 0.0056 - val_accuracy: 0.9655\n",
            "Epoch 273/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0071 - accuracy: 0.9556 - val_loss: 0.0056 - val_accuracy: 0.9653\n",
            "Epoch 274/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0070 - accuracy: 0.9570 - val_loss: 0.0056 - val_accuracy: 0.9654\n",
            "Epoch 275/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0070 - accuracy: 0.9564 - val_loss: 0.0056 - val_accuracy: 0.9658\n",
            "Epoch 276/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0069 - accuracy: 0.9571 - val_loss: 0.0056 - val_accuracy: 0.9657\n",
            "Epoch 277/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0068 - accuracy: 0.9574 - val_loss: 0.0055 - val_accuracy: 0.9657\n",
            "Epoch 278/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0068 - accuracy: 0.9570 - val_loss: 0.0055 - val_accuracy: 0.9661\n",
            "Epoch 279/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0067 - accuracy: 0.9575 - val_loss: 0.0055 - val_accuracy: 0.9659\n",
            "Epoch 280/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0068 - accuracy: 0.9571 - val_loss: 0.0055 - val_accuracy: 0.9658\n",
            "Epoch 281/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0067 - accuracy: 0.9578 - val_loss: 0.0055 - val_accuracy: 0.9661\n",
            "Epoch 282/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0066 - accuracy: 0.9583 - val_loss: 0.0055 - val_accuracy: 0.9665\n",
            "Epoch 283/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0067 - accuracy: 0.9582 - val_loss: 0.0055 - val_accuracy: 0.9664\n",
            "Epoch 284/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0066 - accuracy: 0.9591 - val_loss: 0.0055 - val_accuracy: 0.9663\n",
            "Epoch 285/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0066 - accuracy: 0.9586 - val_loss: 0.0055 - val_accuracy: 0.9664\n",
            "Epoch 286/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0066 - accuracy: 0.9591 - val_loss: 0.0054 - val_accuracy: 0.9664\n",
            "Epoch 287/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0067 - accuracy: 0.9581 - val_loss: 0.0054 - val_accuracy: 0.9663\n",
            "Epoch 288/300\n",
            "60000/60000 [==============================] - 4s 58us/step - loss: 0.0065 - accuracy: 0.9594 - val_loss: 0.0054 - val_accuracy: 0.9667\n",
            "Epoch 289/300\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0065 - accuracy: 0.9590 - val_loss: 0.0054 - val_accuracy: 0.9658\n",
            "Epoch 290/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0065 - accuracy: 0.9594 - val_loss: 0.0054 - val_accuracy: 0.9660\n",
            "Epoch 291/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0065 - accuracy: 0.9596 - val_loss: 0.0054 - val_accuracy: 0.9670\n",
            "Epoch 292/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0065 - accuracy: 0.9595 - val_loss: 0.0054 - val_accuracy: 0.9666\n",
            "Epoch 293/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0064 - accuracy: 0.9600 - val_loss: 0.0054 - val_accuracy: 0.9665\n",
            "Epoch 294/300\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0064 - accuracy: 0.9600 - val_loss: 0.0054 - val_accuracy: 0.9665\n",
            "Epoch 295/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0064 - accuracy: 0.9604 - val_loss: 0.0053 - val_accuracy: 0.9670\n",
            "Epoch 296/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0064 - accuracy: 0.9598 - val_loss: 0.0053 - val_accuracy: 0.9673\n",
            "Epoch 297/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0064 - accuracy: 0.9598 - val_loss: 0.0053 - val_accuracy: 0.9670\n",
            "Epoch 298/300\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0063 - accuracy: 0.9613 - val_loss: 0.0053 - val_accuracy: 0.9674\n",
            "Epoch 299/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0063 - accuracy: 0.9611 - val_loss: 0.0053 - val_accuracy: 0.9671\n",
            "Epoch 300/300\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0063 - accuracy: 0.9602 - val_loss: 0.0053 - val_accuracy: 0.9675\n",
            "Accuracy for  300  epochs:\n",
            "Test loss: 0.005273952848852104\n",
            "Test accuracy: 0.9674999713897705 \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rda2RcCCBkG0",
        "colab_type": "text"
      },
      "source": [
        "## 5. Plot the test loss & test accuracy about the above result(Problem 4: Epochs- 300) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08ZTRiyFkwVz",
        "colab_type": "code",
        "outputId": "ef4017c2-c6af-4a37-d7c9-80545458847b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "source": [
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdFPkxxD9dze",
        "colab_type": "code",
        "outputId": "77d15f02-08cf-4e3b-ff5b-a9798e5698d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['val_loss'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Test loss & accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Test Loss', 'Test Accuracy'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSsKAZrum7kU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}